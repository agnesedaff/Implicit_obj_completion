{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1aydk4TPZgQS-c1lAAXgzdH5EMgqSDSyR","authorship_tag":"ABX9TyNgM350nPlku3vOIxbO1jXZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"s0LgoDJgV9TK"},"outputs":[],"source":["import spacy\n","import pandas as pd\n","import numpy as np"]},{"cell_type":"code","source":["!python -m spacy download it_core_news_lg\n","nlp = spacy.load(\"it_core_news_lg\") #carico il modello per l'italiano"],"metadata":{"id":"CyVIDh6_Dz7i"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nDG5TsBBXOg6"},"source":["Calcolo della similarity tra le annotazioni manuali e i risultati dei modelli"]},{"cell_type":"code","source":["file = pd.read_excel(r'/content/drive/MyDrive/IOcompletion_tesi_agnese_daffara/Dataset/IMPLICIT_results.xlsx')"],"metadata":{"id":"pYYKZTzRnS8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#importo i risultati dei modelli e le annotazioni manuali\n","outputs = [file['BERT-multi'], file['BERT-italian-xxl'], file['UmBERTo'], file['BERTino'], file['ELECTRA-italian']]\n","predicted1 = file['obj_1']\n","predicted2 = file['obj_2']\n","\n","#definisco la funzione per calcolare la similarity\n","def calculate_similarity(word1, word2):\n","  word1_token = nlp(word1)\n","  word2_token = nlp(word2)\n","  if word2 == \"unknown\" or word1 == \"unknown\":\n","      return 0\n","  if word1_token.has_vector and word2_token.has_vector:\n","      similarity = word1_token.similarity(word2_token)\n","      return similarity\n","  else:\n","      return 0\n","\n","#itero sui risultati di ogni modello per ottenere la similarity con il primo e il secondo annotatore e la similarity media\n","print(\"\\ncalcolo della similarity\\n\")\n","count = 0\n","for output in outputs:\n","  count = count+1\n","  print(\"modello\",count)\n","\n","  similarity_scores = []\n","  for pred1, pred2, out in zip(predicted1, predicted2, output):\n","      similarity1 = calculate_similarity(pred1, out)\n","      similarity2 = calculate_similarity(pred2, out)\n","      mean_similarity = np.mean([similarity1, similarity2])\n","      similarity_scores.append(round(mean_similarity, 2))\n","  print(similarity_scores)"],"metadata":{"id":"Tjra96o-uj7F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lemmatizzazione dei risultati e calcolo della similarity"],"metadata":{"id":"SkJmIV5_WYTV"}},{"cell_type":"code","source":["def lemmatize_text(text):\n","    doc = nlp(text)\n","    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n","    return lemmatized_text\n","\n","#lemmatizzo le annotazioni manuali\n","#annotatore 1\n","predicted_lemmatized1 = []\n","for i in predicted1:\n","    predicted_lemmatized1.append(lemmatize_text(i))\n","#print('primo annotatore =', predicted_lemmatized1)\n","predicted_lemmatized2 = []\n","#annotatore2\n","for i in predicted2:\n","    predicted_lemmatized2.append(lemmatize_text(i))\n","#print('secondo annotatore =', predicted_lemmatized2)\n","\n","print(\"\\nrisultati dei modelli lemmatizzati e similarity\\n\")\n","#itero su ogni modello\n","count = 0\n","for output in outputs:\n","  count = count+1\n","  print(\"modello\",count)\n","\n","  #lemmatizzo i risultati del modello\n","  lemmatized = []\n","  for i in output:\n","    lemmatized.append(lemmatize_text(i))\n","  #print(\"output lemmatizzato =\", lemmatized)\n","  #calcolo la media delle similarity\n","  similarity_scores = []\n","  for pred1, pred2, out in zip(predicted_lemmatized1, predicted_lemmatized2, lemmatized):\n","      similarity1 = calculate_similarity(pred1, out)\n","      similarity2 = calculate_similarity(pred2, out)\n","      mean_similarity = np.mean([similarity1, similarity2])\n","      similarity_scores.append(round(mean_similarity, 2))\n","  print(similarity_scores)"],"metadata":{"id":"RtqQlHestYQs"},"execution_count":null,"outputs":[]}]}