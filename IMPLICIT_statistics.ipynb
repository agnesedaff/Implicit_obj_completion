{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JD20C8syu0eAx8VuV5iFsKuHmT5eSo9E","timestamp":1706024409327}],"mount_file_id":"1Me4TyCBtEWSmc1wPJzFHmlHSVavGnrX8","authorship_tag":"ABX9TyN5dUSYr+3g/BAg6Pq+03rg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt"],"metadata":{"id":"M7CCk2Famfmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#importo i dati\n","file = pd.read_excel(r'/content/drive/MyDrive/IOcompletion_tesi_agnese_daffara/Dataset/IMPLICIT_results_lemmatized.xlsx')\n","\n","#creo una variabile con i nomi dei modelli\n","models = [\"GS\", \"BERT-multi\", \"BERT-it\", \"UmBERTo\", \"BERTino\", \"ELECTRA\"]\n","\n","#importo i punteggi di similarity\n","scores = (file['sim_med0'][:600], file['sim_med1'][:600], file['sim_med2'][:600], file['sim_med3'][:600], file['sim_med4'][:600], file['sim_med5'][:600])"],"metadata":{"id":"u7rdsBsImi25"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#visualizzo le medie totali di similarity per ogni modello\n","scores_mean = []\n","for score in scores:\n","  scores_mean.append(np.mean(score))\n","\n","#creo il dataframe con i modelli e i rispettivi similarity scores totali\n","df = pd.DataFrame({'modello': models, 'similarity': scores_mean})\n","df = df.sort_values(by='similarity', ascending=False)\n","print(df)\n","\n","#creo il grafico a barre con Seaborn\n","sns.set(style=\"whitegrid\")\n","plt.figure(figsize=(8, 6))\n","barplot = sns.barplot(x='modello', y='similarity', data=df, palette='viridis', linewidth=0.2, ci=None)\n","for index, value in enumerate(df['similarity']):\n","    barplot.text(index, value + 0.01, round(value, 2), ha='center', color='black', fontsize=10)\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.title(\"similarity score medio del GS e dei modelli (IMPLICIT)\")\n","plt.ylim(0, 1)\n","plt.show()"],"metadata":{"id":"5E_U8vCRRTVf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import scipy.stats as stats\n","from scipy.stats import iqr\n","\n","#calcolo una statistica descrittiva completa per ogni modello\n","\n","#creo il dizionario per il nome del modello e tutte le statistiche\n","results = {}\n","#faccio le misurazioni statistiche che mi interessano per ogni modello\n","for model, score in zip(models, scores):\n","    results[model] = {\n","        'Moda': stats.mode(score),\n","        'Mediana': np.median(score),\n","        'Media': np.mean(score),\n","        'Deviazione Standard': np.std(score),\n","        'Minimo': np.min(score),\n","        'Massimo': np.max(score),\n","        'Campo di Variazione': np.max(score) - np.min(score),\n","        'Scarto Interquartile': iqr(score),\n","        'Scarto Medio Assoluto': np.median(np.abs(score - np.median(score))),\n","        'Varianza': np.var(score),\n","        'Scarto Quadratico Medio': np.std(score),\n","        'Coefficiente di Variazione': (np.std(score) / np.mean(score)) * 100,\n","        'Deviazione Mediana Assoluta': np.median(np.abs(score - np.median(score))),\n","        'Q1': np.percentile(score, 25),\n","        'Q3': np.percentile(score, 75)\n","    }\n","\n","#stampo i risultati\n","for key, value in results.items():\n","    print(f\"\\nResults for {key}:\")\n","    for measure, result in value.items():\n","        print(f\"{measure}: {result}\")"],"metadata":{"id":"rqM1y155nQgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_recall_fscore_support\n","\n","#calcolo precision, recall e fscore dei modelli\n","\n","#prima di eseguire rimuovo dai modelli il GS\n","models = ('BERT-multi', 'BERT-italian-xxl', 'UmBERTo', 'BERTino', 'ELECTRA-italian')\n","#creo una variabile con gli output di ogni modello\n","outputs = [file['BERT-multi'][:600], file['BERT-italian-xxl'][:600], file['UmBERTo'][:600], file['BERTino'][:600], file['ELECTRA-italian'][:600]]\n","#creo le variabili con gli output GS\n","predicted1 = file['obj_1'][:600]\n","predicted2 = file['obj_2'][:600]\n","\n","#definisco la funzione per calcolare le metriche classiche\n","def prec(output):\n","  stat1 = precision_recall_fscore_support(output, predicted1, average= \"weighted\")\n","  stat2 = precision_recall_fscore_support(output, predicted2, average= \"weighted\")\n","  return stat1, stat2\n","\n","count = 0\n","for output in outputs:\n","  count = count + 1\n","  stat = prec(output)\n","  print('\\nmodello', count)\n","  for item in stat:\n","    print('precision:', round(item[0],2))\n","    print('recall:', round(item[1],2))\n","    print('f-measure:', round(item[2],2))"],"metadata":{"id":"rrHlC0xYLPfG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calcolo quali verbi hanno ottenuto una similarity pi√π alta e creo un grafico\n","\n","#creo una variabile con i 30 verbi e una con i punteggi medi su ogni frase\n","verbi = ['ascoltare', 'attendere', 'bere', 'cantare', 'chiamare', 'combattere', 'condurre', 'consumare', 'correre', 'cucinare', 'dirigere', 'disegnare', 'fumare', 'giocare', 'guadagnare', 'guidare', 'leggere', 'mangiare', 'ordinare', 'pagare', 'perdere', 'pregare', 'preoccupare', 'provare', 'respirare', 'scrivere', 'servire', 'suonare', 'tirare', 'vincere']\n","score = file['medie_tot'][:600]\n","\n","#creo una funzione che divide ogni lista in gruppi da 20 scores ciascuno, ogni gruppo si riferisce ad un verbo\n","def verb_values(score):\n","  gruppi = [score[i:i+20] for i in range(0, len(score), 20)]\n","  lista = list(zip(verbi, gruppi))\n","  return lista\n","\n","#applico la funzione ai punteggi medi\n","sis = verb_values(score)\n","\n","#creo il dataframe che associa ogni verbo alla lista di punteggi\n","df = pd.DataFrame(sis, columns=['Verbo', 'Punteggi'])\n","df = df.explode('Punteggi')\n","#tratto i punteggi come float\n","df['Punteggi'] = df['Punteggi'].astype(float)\n","#faccio la media totale per ogni verbo\n","media_per_verbo = df.groupby('Verbo')['Punteggi'].mean().reset_index()\n","#arrotondo a due decimali ogni media\n","media_per_verbo['Punteggi'] = media_per_verbo['Punteggi'].round(2)\n","#print(media_per_verbo)\n","#ordino per punteggio\n","media_per_verbo = media_per_verbo.sort_values(by='Punteggi', ascending=False)\n","\n","#creo il grafico\n","plt.figure(figsize=(10, 8))\n","sns.set_style(\"whitegrid\")\n","plot = sns.barplot(x='Punteggi', y='Verbo', data=media_per_verbo, palette='viridis', order=media_per_verbo['Verbo'])\n","for i, score in enumerate(media_per_verbo['Punteggi']):\n","    rounded_score = round(score, 2)\n","    plot.text(score + 0.01, i, f'{rounded_score}', va='center')\n","plt.title('Similarity score medio per verbo (IMPLICIT dataset: 2 annotatori)')\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.grid(axis='x', linestyle='--', alpha=0.6)\n","plt.xlim(0, 1)\n","plt.show()"],"metadata":{"id":"U2mZHhqyB5p5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calcolo le medie per verbo sull'annotazione manuale\n","score = file['sim_med0'][:600]\n","\n","#divido i punteggi in gruppi da 20 con la funzione definita sopra\n","sis = verb_values(score)\n","#creo il dataframe\n","df = pd.DataFrame(sis, columns=['Verbo', 'Punteggi'])\n","df = df.explode('Punteggi')\n","#tratto i punteggi come float\n","df['Punteggi'] = df['Punteggi'].astype(float)\n","#calcolo la media per ogni verbo e arrotondo a due decimali\n","media_per_verbo = df.groupby('Verbo')['Punteggi'].mean().reset_index()\n","media_per_verbo['Punteggi'] = media_per_verbo['Punteggi'].round(2)\n","#ordino per punteggio\n","media_per_verbo = media_per_verbo.sort_values(by='Punteggi', ascending=False)\n","\n","#creo il grafico\n","plt.figure(figsize=(10, 8))\n","sns.set_style(\"whitegrid\")\n","plot = sns.barplot(x='Punteggi', y='Verbo', data=media_per_verbo, palette='viridis', order=media_per_verbo['Verbo'])\n","for i, score in enumerate(media_per_verbo['Punteggi']):\n","    rounded_score = round(score, 2)\n","    plot.text(score + 0.01, i, f'{rounded_score}', va='center')\n","plt.title('Similarity score medio per verbo (IMPLICIT dataset: 2 annotatori)')\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.grid(axis='x', linestyle='--', alpha=0.6)\n","plt.xlim(0, 1)\n","plt.show()"],"metadata":{"id":"3YkuAPY-ake0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Da qui in poi si usa per calcolare la correlazione tra le varie features dei verbi (tipo azionale, classe semantica) e la similarity."],"metadata":{"id":"jEyacNvbo811"}},{"cell_type":"code","source":["from scipy.stats import pearsonr\n","\n","#carico l'ontologia con le features dei verbi e i punteggi medi ottenuti\n","df = pd.read_excel('/content/drive/MyDrive/IOcompletion_tesi_agnese_daffara/Dataset/Ontologia_pattern/IO_clean.xlsx')"],"metadata":{"id":"3U4fcR4XchnD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calcolo la correlazione tra tipo di Defaulting e punteggio di similarity\n","\n","var1 = df[\"LD\"]\n","var2 = df[\"Similarity_imp\"]\n","\n","corr_coef, p_value = stats.pearsonr(var1, var2)\n","print(\"Coefficienti di correlazione di Pearson:\", corr_coef)\n","print(\"P-value associati:\", p_value)"],"metadata":{"id":"8XzMs9SJHr77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calcolo la correlazione tra range di Oggetti e punteggio di similarity\n","\n","var1 = df[\"Range\"]\n","var2 = df[\"Similarity_imp\"]\n","\n","corr_coef, p_value = stats.pearsonr(var1, var2)\n","print(\"Coefficienti di correlazione di Pearson:\", corr_coef)\n","print(\"P-value associati:\", p_value)"],"metadata":{"id":"7TK5nMayDFWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#calcolo la correlazione tra tipo di Defaulting e range di Oggetti\n","\n","var1 = df[\"PD\"]\n","var2 = df[\"Range\"]\n","\n","corr_coef, p_value = stats.pearsonr(var1, var2)\n","print(\"Coefficienti di correlazione di Pearson:\", corr_coef)\n","print(\"P-value associati:\", p_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sn0GZuMcd6sP","executionInfo":{"status":"ok","timestamp":1709923203231,"user_tz":-60,"elapsed":299,"user":{"displayName":"AGNESE DAFFARA","userId":"11645510188886615281"}},"outputId":"654d8202-9605-4b8a-80f4-89a01ee03c05"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Coefficienti di correlazione di Pearson: 0.6287500475631085\n","P-value associati: 0.0001982995186486977\n"]}]},{"cell_type":"code","source":["from scipy.stats import f_oneway\n","\n","#test oneway ANOVA per verificare l'effetto delle classi verbali sulla similarity\n","result_tipo = f_oneway(*[df['Similarity_imp'][df['Tipo_azionale'] == feature] for feature in df['Tipo_azionale'].unique()])\n","print('Influenza del tipo azionale')\n","print(\"ANOVA F-statistic:\", result_tipo.statistic)\n","print(\"ANOVA p-value:\", result_tipo.pvalue)\n","\n","result_tipo_exp = f_oneway(*[df['Similarity_exp'][df['Tipo_azionale'] == feature] for feature in df['Tipo_azionale'].unique()])\n","print('\\nInfluenza del tipo azionale (exp)')\n","print(\"ANOVA F-statistic:\", result_tipo_exp.statistic)\n","print(\"ANOVA p-value:\", result_tipo_exp.pvalue)\n","\n","result_classe = f_oneway(*[df['Similarity_imp'][df['Classe_semantica'] == feature] for feature in df['Classe_semantica'].unique()])\n","print('\\nInfluenza della classe semantica')\n","print(\"ANOVA F-statistic:\", result_classe.statistic)\n","print(\"ANOVA p-value:\", result_classe.pvalue)\n","\n","result_classe_exp = f_oneway(*[df['Similarity_exp'][df['Classe_semantica'] == feature] for feature in df['Classe_semantica'].unique()])\n","print('\\nInfluenza della classe semantica (exp)')\n","print(\"ANOVA F-statistic:\", result_classe_exp.statistic)\n","print(\"ANOVA p-value:\", result_classe_exp.pvalue)"],"metadata":{"id":"OXOJ6fykqO_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from statsmodels.stats.multicomp import pairwise_tukeyhsd\n","import statsmodels.api as sm\n","\n","#faccio il test di Tukey per vedere la differenza tra classi semantiche\n","\n","#stampo la tabella ANOVA\n","anova_model = sm.formula.ols('Similarity_imp ~ Classe_semantica', data=df).fit()\n","anova_table = sm.stats.anova_lm(anova_model, typ=2)\n","print(\"Tabella ANOVA:\")\n","print(anova_table)\n","\n","#eseguo il test di Tukey\n","tukey_results = pairwise_tukeyhsd(df['Similarity_imp'], df['Classe_semantica'])\n","print(\"\\nRisultati del test di Tukey:\")\n","print(tukey_results)\n","\n","#visualizzo i risultati\n","tukey_results.plot_simultaneous()"],"metadata":{"id":"4jqSX0qM9nDk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#faccio il test di Tukey per vedere la differenza tra tipi azionali\n","\n","#stampo la tabella anova\n","anova_model = sm.formula.ols('Similarity_imp ~ Tipo_azionale', data=df).fit()\n","anova_table = sm.stats.anova_lm(anova_model, typ=2)\n","print(\"Tabella ANOVA:\")\n","print(anova_table)\n","\n","#eseguo il test di Tukey\n","tukey_results = pairwise_tukeyhsd(df['Similarity_imp'], df['Tipo_azionale'])\n","print(\"\\nRisultati del test di Tukey:\")\n","print(tukey_results)\n","\n","#visualizzo i risultati\n","tukey_results.plot_simultaneous()"],"metadata":{"id":"WEQ0EfDMmu5H"},"execution_count":null,"outputs":[]}]}