{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M7CCk2Famfmv"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u7rdsBsImi25"},"outputs":[],"source":["#importo i dati da drive\n","file = pd.read_excel(r'/content/drive/MyDrive/IOcompletion_tesi_agnese_daffara/Dataset/EXPLICIT_results.xlsx')\n","\n","models = [\"BERT-multi\", \"BERT-it\", \"UmBERTo\", \"BERTino\", \"ELECTRA\"]\n","scores = (file['similarity1'][:600], file['similarity2'][:600], file['similarity3'][:600], file['similarity4'][:600], file['similarity5'][:600]) #importo i punteggi di similarity"]},{"cell_type":"code","source":["#calcolo il range di Oggetti per verbo nell'annotazione manuale\n","\n","verbi = ['ascoltare', 'attendere', 'bere', 'cantare', 'chiamare', 'combattere', 'condurre', 'consumare', 'correre', 'cucinare', 'dirigere', 'disegnare', 'fumare', 'giocare', 'guadagnare', 'guidare', 'leggere', 'mangiare', 'ordinare', 'pagare', 'perdere', 'pregare', 'preoccupare', 'provare', 'respirare', 'scrivere', 'servire', 'suonare', 'tirare', 'vincere']\n","\n","#creo una funzione che divide ogni lista in gruppi da 20 scores ciascuno, ogni gruppo si riferisce ad un verbo\n","def verb_values(score):\n","  gruppi = [score[i:i+20] for i in range(0, len(score), 20)]\n","  lista = list(zip(verbi, gruppi))\n","  return lista\n","\n","#creo una variabile che contiene le due liste di Oggetti GS\n","ress = [predicted1]\n","#creo una lista che contiene tutti i risultati divisi in gruppi\n","results = []\n","results.append(verb_values(ress))\n","#creo un dizionario che contiene i verbi e i punteggi che hanno ottenuto in ogni lista\n","d={}\n","for verbo in verbi:\n","  d[verbo] = []\n","#itero su ogni lista di risultati\n","for l in results:\n","  for item in l:\n","    #appendo alla value del verbo tutti gli score dei modelli per quel verbo\n","    d[item].append(item)\n","\n","#definisco una funzione per contare le parole uniche per ogni verbo\n","def conta_parole_uniche(d):\n","    risultati = {}\n","    for verbo, liste_parole in d.items():\n","        parole_uniche = set()\n","        for serie in liste_parole:\n","            parole_uniche.update(serie)\n","        numero_parole_uniche = len(parole_uniche)\n","        risultati[verbo] = numero_parole_uniche\n","    return risultati\n","\n","#applico la funzione al dizionario\n","risultati = conta_parole_uniche(d)\n","\n","#creo il dataframe ordinato\n","df = pd.DataFrame(list(risultati.items()), columns=['Verbo', 'Range'])\n","df_sorted = df.sort_values(by='Range', ascending=False)\n","\n","#creo il grafico\n","sns.set_style(\"whitegrid\")\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='Range', y='Verbo', data=df_sorted, palette='viridis')\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.title(\"Range di Oggetti (IMPLICIT dataset: 2 annotatori)\")\n","plt.xticks(range(0, int(df['Range'].max()) + 1, 1))\n","plt.show()"],"metadata":{"id":"AHIY3l8TGaJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5E_U8vCRRTVf"},"outputs":[],"source":["#visualizzo le medie totali di similarity per ogni modello\n","\n","scores_mean = []\n","for sc in scores:\n","  scores_mean.append(np.mean(sc))\n","\n","#creo il dataframe con i modelli e i rispettivi similarity scores totali\n","df = pd.DataFrame({'modello': models, 'similarity': scores_mean})\n","df = df.sort_values(by='similarity', ascending=False)\n","print(df)\n","\n","#creo il grafico a barre con Seaborn\n","sns.set(style=\"whitegrid\")\n","plt.figure(figsize=(8, 6))\n","barplot = sns.barplot(x='modello', y='similarity', data=df, palette='viridis', linewidth=0.2, ci=None)\n","for index, value in enumerate(df['similarity']):\n","    barplot.text(index, value + 0.01, round(value, 2), ha='center', color='black', fontsize=10)\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.title('similarity score medio per modello (EXPLICIT)')\n","plt.ylim(0, 1)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rqM1y155nQgS"},"outputs":[],"source":["from scipy.stats import iqr\n","from scipy.stats import stats\n","\n","#calcolo una statistica descrittiva completa per ogni modello\n","\n","results = {} #creo il dizionario per il nome del modello e tutte le statistiche\n","for model, score in zip(models, scores): #faccio le misurazioni statistiche che mi interessano per ogni modello\n","    results[model] = {\n","        'Moda': stats.mode(score),\n","        'Mediana': np.median(score),\n","        'Media': np.mean(score),\n","        'Deviazione Standard': np.std(score),\n","        'Minimo': np.min(score),\n","        'Massimo': np.max(score),\n","        'Campo di Variazione': np.max(score) - np.min(score),\n","        'Scarto Interquartile': iqr(score),\n","        'Scarto Medio Assoluto': np.median(np.abs(score - np.median(score))),\n","        'Varianza': np.var(score),\n","        'Scarto Quadratico Medio': np.std(score),\n","        'Coefficiente di Variazione': (np.std(score) / np.mean(score)) * 100,\n","        'Deviazione Mediana Assoluta': np.median(np.abs(score - np.median(score))),\n","        'Q1': np.percentile(score, 25),\n","        'Q3': np.percentile(score, 75)\n","    }\n","\n","#stampo i risultati\n","for key, value in results.items():\n","    print(f\"\\nResults for {key}:\")\n","    for measure, result in value.items():\n","        print(f\"{measure}: {result}\")"]},{"cell_type":"markdown","metadata":{"id":"uBlwZaJ7UW1o"},"source":["Questo calcola precision, recall e fscore dei modelli"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qcQ6R9v4UW1p"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support\n","\n","#questo calcola precision, recall e fscore dei modelli\n","#calcolo precision, recall e fscore dei modelli\n","\n","outputs = [file['BERT-multi'][:600], file['BERT-italian-xxl'][:600], file['UmBERTo'][:600], file['BERTino'][:600], file['ELECTRA-italian'][:600]]\n","predicted = file['GS_Obj']\n","\n","count = 0\n","for output in outputs:\n","  count = count + 1\n","  stat = precision_recall_fscore_support(output, predicted, average= \"weighted\")\n","  print('\\nmodello', count)\n","  print('precision:', round(stat[0],2))\n","  print('recall:', round(stat[1],2))\n","  print('f-measure:', round(stat[2],2))"]},{"cell_type":"markdown","metadata":{"id":"_ydXmx_ZUW1q"},"source":["Qui calcoliamo quali verbi sono stati pi√π facili da riempire"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kj1g1R9bUW1r"},"outputs":[],"source":["#qui creiamo un plot che ci dice su che verbi i modelli hanno performato meglio\n","\n","verbi = ['ascoltare', 'attendere', 'bere', 'cantare', 'chiamare', 'combattere', 'condurre', 'consumare', 'correre', 'cucinare', 'dirigere', 'disegnare', 'fumare', 'giocare', 'guadagnare', 'guidare', 'leggere', 'mangiare', 'ordinare', 'pagare', 'perdere', 'pregare', 'preoccupare', 'provare', 'respirare', 'scrivere', 'servire', 'suonare', 'tirare', 'vincere']\n","score = file['media_tot'][:600]\n","\n","def verb_values(score): #creo una funzione che divide ogni lista in gruppi da 20 scores ciascuno, ogni gruppo si riferisce ad un verbo\n","  gruppi = [score[i:i+20] for i in range(0, len(score), 20)]\n","  lista = list(zip(verbi, gruppi))\n","  return lista\n","\n","sis = verb_values(score)\n","\n","df = pd.DataFrame(sis, columns=['Verbo', 'Punteggi'])\n","df = df.explode('Punteggi')\n","df['Punteggi'] = df['Punteggi'].astype(float)\n","media_per_verbo = df.groupby('Verbo')['Punteggi'].mean().reset_index()\n","media_per_verbo['Punteggi'] = media_per_verbo['Punteggi'].round(2)\n","print(media_per_verbo)\n","media_per_verbo = media_per_verbo.sort_values(by='Punteggi', ascending=False)\n","\n","plt.figure(figsize=(10, 8))\n","sns.set_style(\"whitegrid\")\n","plot = sns.barplot(x='Punteggi', y='Verbo', data=media_per_verbo, palette='viridis', order=media_per_verbo['Verbo'])\n","for i, score in enumerate(media_per_verbo['Punteggi']):\n","    rounded_score = round(score, 2)\n","    plot.text(score + 0.01, i, f'{rounded_score}', va='center')\n","plt.title('Similarity score medio per verbo (EXPLICIT dataset)')\n","plt.xlabel('')\n","plt.ylabel('')\n","plt.grid(axis='x', linestyle='--', alpha=0.6)\n","plt.xlim(0, 1)\n","plt.show()"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1JD20C8syu0eAx8VuV5iFsKuHmT5eSo9E","authorship_tag":"ABX9TyO2P03rWJ2CiAfIRe6R326t"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}