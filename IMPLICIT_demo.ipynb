{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agnesedaff/Implicit_obj_completion/blob/Script/IMPLICIT_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfKfNp3QICBz"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC16tX_apeJj"
      },
      "outputs": [],
      "source": [
        "#carico il modello per l'italiano\n",
        "!python -m spacy download it_core_news_lg\n",
        "nlp = spacy.load(\"it_core_news_lg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHpl0Yr3Qfx8"
      },
      "outputs": [],
      "source": [
        "#imposto il modello BERT da usare con la libreria pipeline\n",
        "unmasker = pipeline('fill-mask', model=\"dbmdz/bert-base-italian-xxl-cased\", tokenizer = \"dbmdz/bert-base-italian-xxl-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HonV_0_BoWkd"
      },
      "source": [
        "**Primo step:** otteniamo i risultati dei modelli sul task di fill-mask\n",
        "\n",
        "Le istruzioni per il modello sono:\n",
        "\n",
        "1.   riempi il primo [MASK] con un Determiner e crea una nuova frase con un solo [MASK]\n",
        "2.   riempi il secondo [MASK] con un Noun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYYKZTzRnS8U"
      },
      "outputs": [],
      "source": [
        "#importo le frasi del dataset dal file drive\n",
        "file = pd.read_excel(r'/content/drive/MyDrive/IOcompletion_tesi_agnese_daffara/Dataset/IMPLICIT_results.xlsx')\n",
        "sentences = file['frase']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7cBB5sd1pc2"
      },
      "outputs": [],
      "source": [
        "#creo due liste con gli output e i prediction scores\n",
        "output = []\n",
        "scores = []\n",
        "#itero su ogni frase nel dataset\n",
        "for sentence in sentences:\n",
        "    #setto il numero di predizioni a 10\n",
        "    results = unmasker(sentence, top_k=10)\n",
        "    det_predictions = []\n",
        "    #cerco se è disponibile un Determiner per il primo [MASK]\n",
        "    for prediction in results[0]:\n",
        "        #avvio l'analisi della parola con SpaCy\n",
        "        doc = nlp(prediction[\"token_str\"])\n",
        "        for token in doc:\n",
        "            if token.pos_ == \"DET\":\n",
        "                det_predictions.append(prediction)\n",
        "    if det_predictions:\n",
        "            #aggiungo il token con POS = DET più probabile alla variabile 'det_predictions'\n",
        "            det_predictions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "            determiner = det_predictions[0][\"token_str\"]\n",
        "            #sostituisco il Determiner al primo [MASK] e creo una nuova frase con un solo [MASK]\n",
        "            new_sentence = sentence.replace(\"[MASK]\", determiner, 1)\n",
        "    else:\n",
        "            new_sentence = sentence.replace(\"[MASK]\", \"\", 1)\n",
        "\n",
        "    #cerco un Noun per il secondo [MASK]\n",
        "    #setto il numero di predizioni a 20\n",
        "    results_new = unmasker(new_sentence, top_k=20)\n",
        "    noun_predictions = []\n",
        "    for prediction in results_new:\n",
        "        doc = nlp(prediction['token_str'])\n",
        "        for token in doc:\n",
        "            if token.pos_ == \"NOUN\":\n",
        "                noun_predictions.append(prediction)\n",
        "    if noun_predictions:\n",
        "        #aggiungo il token con POS = NOUN più probabile alla variabile 'noun_predictions'\n",
        "        noun_predictions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
        "        output.append(noun_predictions[0][\"token_str\"])\n",
        "        #aggiungo il prediction score alla variabile 'scores'\n",
        "        scores.append(round(noun_predictions[0][\"score\"],2))\n",
        "    else:\n",
        "        output.append(\"unknown\")\n",
        "        scores.append(\"unknown\")\n",
        "\n",
        "#stampo gli output e i prediction scores\n",
        "print(output)\n",
        "print(scores)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XWeaBTNXh_WEbnMTTh-W3zMa3QfCF-kI",
      "authorship_tag": "ABX9TyOa3X0HmXMt27mi9nXv0nsN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}